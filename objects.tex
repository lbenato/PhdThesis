\section{Event selection}
\label{sec:objects}

In this section, a list of the selections applied to the physics objects used in the analysis is presented, together with performance and validation plots. 
%%The objects are selected according to the standard Run2 reccomendations provided by the various POGs for the Summer16 (25ns) MiniAOD-v2 (Moriond reccomendations).
%The version of CMSSW used for the analysis is {\tt CMSSW\_8\_0\_25}.

\subsection{Vertex and Pile-up}
Due to the pile-up effect, several primary vertices are typically reconstructed in an event. The primary vertex of the event is defined as the one with the highest sum of transverse momenta $\sum \pt^2$ of clustered physics objects associated to it, which passes the following selections:
\begin{itemize}
  \item number of degrees of freedom $N_{DoF}>4$
  \item vertex position along the beampipe $|z_{vtx}|<24\cm$
  \item vertex distance with respect the beam pipe $d_0<2\cm$
\end{itemize}
where $z_{vtx}$ and $d_0$ are the distance along and perpendicular to the beam line of the vertex with respect the nominal interaction point $(0,0,0)$.

\noindent The Monte Carlo samples listed in sec.~\ref{sec:samples} are generated simulating the pile-up conditions, as expected in the 25 ns bunch crossing pile-up scenario. Nevertheless, the MC pile-up description does not match exactly the conditions in data, and there is therefore the need to reweight the simulated events in order to improve the agreement with the data. 

\noindent The MC samples are reweighted assuming a total inelastic cross section of $\sigma_{in} = 69\,200 \mu b$. The comparison between the distributions of primary vertices in data and MC after the pile-up reweighting is applied is shown in fig.~\ref{fig:npv} for an event selection (called inclusive selection) requiring large amount of \met recoiling against an AK8 fat jet~(tab.~\ref{tab:sel}).
 
 \begin{figure}[!htb]
  \centering
    \includegraphics[width=.495\textwidth]{plots/v9_U/XVZnnInc/nPV.pdf}
  \caption{Primary vertices distributions in data and MC samples, after reweighting.}
  \label{fig:npv}
 \end{figure}


\subsection{Electrons}\label{ssec:electrons}
%{\color{red} How the electrons are reconstructed: The electron identification variables that have been found to be the most powerful, and are used in the selection, are: the energy-momentum match between the seed cluster and the trackE seed/pin, the variables measuring spatial matching between the track and the supercluster, ∆ηin and ∆φin, the supercluster η width,σiη iη(as taken from the covariance matrix using logarithmic weights), and the hadronic leakage variable H/E. The supercluster η width is to a very good approximation unaffected by the spreading due to the magnetic field of the showering in the tracker material.\\ Isolation variables are computed in three sub-detectors: the tracker, the ECAL, and the HCAL. Transverse energy/momentum sums are evaluated in regions of ∆R<0.3. As electrons undergo bremsstrahlung energy loss in the tracker material, care is taken to remove from the isolation sums the contributions from bremsstrahlung photons and possible resulting conversion electrons.}

Electrons used in this analysis, reconstructed from energy deposits in the ECAL matched to tracks reconstructed in the silicon tracker, are required to pass the Particle-Flow criteria, and to fall in the ECAL pseudorapidity fiducial range ($|\eta|<2.5$). The electron identification is defined with a ``cut-based'' approach. In the isolation definition the effect of pile-up is considered by taking into account the energy deposits in the calorimeter, estimated through the so-called \emph{$\rho$-area} method, by subtracting the median energy density in the event $\rho$ multiplied by electron effective area. The isolation value is computed in a $\Delta$R cone of 0.3 centered along the lepton direction.

\noindent Since in this analysis aims at a final state without any lepton, every electron identified with the looser cut-based criteria (\emph{veto Id}), transverse momentum $\pt > 10$ GeV is vetoed. The detailed set of cuts to define a \emph{veto} cut-based Id electron are reported in tab.~\ref{tab:EGcutBar}; this set of selctions allow to identify an electron with an efficiency of $\sim 95$\%. The supercluster width is indicated as $\sigma_{i\eta i\eta}$; $\Delta \eta_{in}^{seed}$ and $\Delta \phi_{in}$ are the difference in $\eta$ and $\phi$ between the track position as it is measured in the inner layer, and then extrapolated to the interaction vertex and to the calorimeter, and the $\eta$ of the seed cluster or the $\phi$ of the supercluster; $H/E$ is the hadronic leakage, \textit{i.e.} the ratio of the hadronic energy of the calorimetric towers to the electromagnetic energy of the electron supercluster; \emph{relIso} indicates the relative isolation calculated with the effective area approach; $1/E - 1/p$ is the difference of the inverse of the energy and the momentum; $d_0$ and $d_z$ are the transverse and longitudinal impact parameters. A dedicated conversion veto is applied to mitigate the effects of electrons undergoing bremsstrahlung in the silicon detector.

\begin{table}[htb]
 \centering
    \begin{tabular}{lccc}
     \hline

    Electrons                   &        & \multicolumn{2}{c}{\texttt{Veto}}\\
                                &        & EB      & EE     \\
 \hline
    $\sigma_{i\eta i\eta} $     & $ < $  &0.0115   &0.037  \\
    $\Delta \eta_{in}^{seed}$   & $ < $  &0.00749  &0.00895 \\
    $\Delta \phi_{in} $      & $ < $  &0.228    &0.213   \\
    $H/E $                      & $ < $  &0.356    &0.211   \\
    relIso (Effective Area)                 & $<$    &0.175    &0.159   \\
    $|1/E - 1/p|$               & $ < $  &0.299    &0.15    \\
    $|d_0|$                     & $ < $  &0.05     &0.10   \\
    $|d_z|$                     & $ < $  &0.10     &0.20   \\
    missing hits                & $\leq$ &2        &3       \\
    conversion veto             &        &  yes    &yes     \\
    
 \hline
\end{tabular}
\caption{Electron cut-based selection for 25 ns bunch spacing conditions. EB: barrel cuts ( $|\eta_\text{supercluster}| \leq 1.479$); EE: endcap cuts ( $|\eta_\text{supercluster}| > 1.479$)}
\label{tab:EGcutBar}
\end{table}

%Per-event data-MC scale factors for electron identification are calculated and applied in the analysis.
%\clearpage

\subsection{Photons}
As in the case of electrons, a photon veto is applied in the analysis both for the signal and the control regions. Events are rejected if they contains one (or more) photon with $\pt > 15$ GeV , $|\eta| < 2.5$, passing the \texttt{Loose} cut-based photon Id, whose definition is reported in tab.~\ref{tab:PhotonId}. The isolation cuts (using the rho-area method for the mitigation of the pileup) and conversion safe electron veto are applied. The isolation value is computed in a $\Delta R$ cone of 0.3 and is corrected for pileup by subtracting the event-by-event energy density ($\rho$) times an effective area.

 \begin{table}[htb]
  \centering
     \begin{tabular}{lccc}
      \hline
 
     Photons                                   &       & \multicolumn{2}{c}{\texttt{Loose}}\\
                                               &       & EB      & EE  \\
  \hline
     $H/E $                                    & $ < $ &0.0597   & 0.0481      \\
     $\sigma_{i\eta i\eta} $                   & $ < $ &0.01031  & 0.03013   \\
     PF ch.had.iso.($\rho$-corr)               & $ < $ &1.295    & 1.011   \\
     PF neu.had.iso.($\rho$-corr)              & $ < $ &$10.910+0.0148\pt+0.000017\pt^2$    &$5.931+0.0163\pt+0.000014\pt^2 $   \\
     PF photon iso.($\rho$-corr)               & $ < $ &$3.630+0.0047\pt$                 &$6.641+0.0034\pt $   \\
     conversion veto                           &       & yes     &yes     \\
  \hline
 \end{tabular}
  \caption{Photon cut-based selection for 25 ns bunch spacing conditions. EB: barrel cuts ( $|\eta_\text{supercluster}| \leq 1.479$); EE: endcap cuts ( $|\eta_\text{supercluster}| > 1.479$)}\label{tab:PhotonId}
 \end{table}

%Scale factors for photon identification (including isolation) are provided by Egamma POG, derived for 80X (Moriond 17 recommendation), that can be found in~\cite{EGammaPOG_ele_SF}.

\subsection{Muons}\label{ssec:muons}

%Tracker Muon reconstruction is more efficient than the Global Muon reconstruction at low momenta, $\pt \lesssim 5 \GeV$, because it requires only a single muon segment in the muon system, whereas Global Muon reconstruction is designed to have high efficiency for muons penetrating through more than one muon station and typically requires segments in at least two muon stations. Thanks to the high tracker-track efficiency and a very high efficiency of reconstructing segments in the muon system, about 99\% of muons produced in $pp$ collisions and having sufficiently high momentum are reconstructed either as a Global Muon or a Tracker Muon, and very often as both. Muons reconstructed only as standalone-muon tracks have worse momentum resolution and less favorable collision muon to cosmic-ray muon ratio than the Global and Tracker Muons and are usually not used in physics analyses.

The minimal criteria to define a muon is that it must be identified by the Particle-Flow algorithm, and should be reconstructed either as a global muon or as a tracker muon (sec.~\ref{ssec:physicsobjects}). The muon isolation is defined in cone with a radius of $\Delta R=0.4$ centered along the lepton direction. In the analysis event selection, all muons identified with the loosest criteria previously described, \pt over 10 GeV, PF isolation below 0.25, $\eta<|2.4|$ are vetoed.
 
%Scale factors for muon identification and isolation are centrally provided as a function of the muon \pt and $\eta$ by the Muon POG~\cite{MuonSF}, and are applied consistently in the analysis.


\subsection{Taus}\label{sec:tau}
The presence of hadronically-decaying taus only act as veto for the events both in the signal and in the control regions to suppress electroweak backgrounds. The selection criteria for taus are $\pt > 18$ GeV and $|\eta| < 2.3$. Loose identification criteria of the hadronic tau reconstruction algortihms are required and applied in order to identify possible tau candidates.


\subsection{Jets}\label{ssec:jets}
In this analysis, jets are considered if the corrected \pt is larger than 30 \GeV for AK4 jets and 200\GeV for AK8 jets, and lie in the tracker acceptance ($|\eta|<2.4$). Additionally, AK4 jets are required to pass \emph{loose} jet identification requirements, AK8 are required to pass \emph{tight} jet identification requirements defined in tab.~\ref{tab:JetId}. AK8 jets are used to reconstruct the hadronically decaying electroweak boson candidate, whilst AK4 jets are used to suppress the contribution of top and QCD background events. Jet energy corrections are applied to AK4 and AK8 CHS jets. Fig.~\ref{fig:n_AK8}-~\ref{fig:AK8jet_eta} show the data/simulation comparison after the analysis selections~(tab.~\ref{tab:sel} without Top cleaning and Event cleaning).

\begin{table}[htb]
 \centering
 \begin{tabular}{lll}
\hline
PF Jet ID                       & \emph{loose}   & \emph{tight}   \\
\hline
Neutral Hadron Fraction         & $< 0.99  $     & $< 0.90  $    \\
Neutral EM Fraction             & $< 0.99  $     & $< 0.90  $\\
Number of Constituents          & $> 1     $     & $> 1     $\\
Muon Fraction                   & \--            & \-- \\
\hline
\multicolumn{3}{l}{Additionally, for $|\eta| < 2.4$ } \\
\hline
Charged Hadron Fraction         & $> 0   $& $> 0   $\\
Charged Multiplicity            & $> 0   $& $> 0   $\\
Charged EM Fraction             & $< 0.99$& $< 0.99$\\
\hline
 \end{tabular}
 \caption{ \emph{Loose} and \emph{Tight} jet identification requirements for 25 ns bunch spacing conditions.\label{tab:JetId}}
\end{table}

\begin{figure}[!htb]
  \begin{center}
    \includegraphics[width=.495\textwidth]{plots/v9_U/XVZnnInc/nFatJets.pdf}
  \end{center}
  \caption{Number of reconstructed AK8 jets after selections.}
  \label{fig:n_AK8}
\end{figure}

\begin{figure}[!htb]
  \begin{center}
    \includegraphics[width=.495\textwidth]{plots/v9_U/XVZnnInc/FatJet1_pt.pdf}
  \end{center}
  \caption{Leading AK8 jet \pt spectra after selections.}
  \label{fig:AK8jet_pt}
\end{figure}

\begin{figure}[!htb]
  \begin{center}
    \includegraphics[width=.495\textwidth]{plots/v9_U/XVZnnInc/FatJet1_eta.pdf}
  \end{center}
  \caption{Leading AK8 jet $\eta$ spectra after selections.}
  \label{fig:AK8jet_eta}
\end{figure}

\noindent Since it has been measured that the jet energy resolution (JER) is not the same in data and MC, an additional smearing is applied in simulation, in order to get a better agreement. There are two independent ways to get the smearing. The scaling method rescales the corrected four-momentum of a reconstructed jet by a factor
\begin{equation}
c_{\text{JER}} = 1 + (s_{\text{JER}} - 1) \frac{p_T - p_T^{\text{gen}}}{p_T},
\end{equation}
where \pt is the transverse momentum of the jet, $p_T^{\text{gen}}$ is the transverse momentum of the generator level particle corresponding to the reconstructed jet, and $s_{\text{JER}}$ is the data-simulation resolution scale factor. The factor $c_{\text{JER}}$ is positively defined, hence if negative it is set equal to zero. %This method only works if a well-matched particle-level jet is present and can result in a large shift of the response otherwise.
The generator level particle and a reconstructed jet are defined as matched if:
\begin{equation}
\Delta R < R_{\text{cone}} / 2, |p_T - p_T^{\text{ptcl}}| < 3 \sigma_{\text{JER}} p_{T},
\end{equation}
where $R_{\text{cone}}$ is the jet clustering parameter and $\sigma_{\text{JER}}$ is the relative \pt resolution measured in simulation.

\noindent The alternative approach is the stochastic smearing, and it does not require the matching with the generator level particle. The jet four-momentum is rescaled by a factor
\begin{equation}
c_{\text{JER}} = 1 + \mathcal{N}(0, \sigma_{\text{JER}}) \sqrt{max(s_{\text{JER}}^2 - 1, 0)},
\end{equation}
where $\sigma_{\text{JER}}$ is the relative \pt resolution in simulation, $s_{\text{JER}}$ is the data-simulation scale factor, and $\mathcal{N}(0, \sigma)$ 
is a random number extracted from a gaussian normal distribution, whose mean is zero and variance $\sigma^2$. Scaling factor $c_{\text{JER}}$ is positively defined.% This method only allows to degrade the resolution.

\noindent The smearing procedure adopted in this analysis is the hybrid method: when a matching jet at generator level is found, the scaling method is adopted, else the stochastic smearing is chosen. The smearing coefficients (scale factors, SF) as a function of the jet $\eta$ and their uncertainties are reported in tab.~\ref{tab:smear} for 2016 data.

\begin{table}[!htb]
  \centering
  \begin{tabular}{l|ccccccc}
    Jet $\eta$ & Smearing SF \\
    \hline
    $0.0-0.5$ & $1.109 \pm 0.008$ \\
    $0.5-0.8$ & $1.138 \pm 0.013$ \\
    $0.8-1.1$ & $1.114 \pm 0.013$ \\
    $1.1-1.3$ & $1.123 \pm 0.024$ \\
    $1.3-1.7$ & $1.084 \pm 0.011$ \\
    $1.7-1.9$ & $1.084 \pm 0.011$ \\
    $1.9-2.1$ & $1.140 \pm 0.047$ \\
    $2.1-2.3$ & $1.067 \pm 0.053$ \\
    $2.3-2.5$ & $1.177 \pm 0.041$ \\
    $2.5-2.8$ & $1.364 \pm 0.039$ \\
    $2.8-3.0$ & $1.857 \pm 0.071$ \\
    $3.0-3.2$ & $1.328 \pm 0.022$ \\
    $3.2-5.0$ & $1.16  \pm 0.029$ \\
  \end{tabular}
  
  \caption{Data-simulation jet smearing coefficients and their corresponding uncertainties.}
  \label{tab:smear}
\end{table}

\subsection{Jet mass}\label{ssec:jetmass}

The jet mass is the main observable in distinguishing a \V jet from a jet produced by colour interaction (QCD jets). Jet grooming procedure consists in the suppression of uncorrelated underlying event, pile-up and soft radiation from the jet and improves the discrimination, by pushing the jet mass for QCD jets towards lower values while maintaining the jet mass for \V-jets around the electroweak boson mass window.

\noindent The grooming technique of the analysis relies on the ``soft drop declustering'' algorithm, a jet substructure technique that recursively removes soft wide-angle radiation from a jet~\cite{Larkoski:2014wba}, in order to mitigate the contaminations from initial state radiation, along with pile-up and multiple scatterings. The soft drop algorithm is described by two parameters, a soft threshold $z_{\text{cut}}$ and an angular exponent $\beta$. Starting with a jet of radius $R_0$ with only two constituents, the soft drop algorithm removes the soft constituent until the soft drop condition holds:
\begin{equation}
\frac{\min(\pt^1,\pt^2)}{\pt^1+\pt^2} > z_{cut} \left( \frac{\Delta R_{12}}{R_0} \right)^\beta,
\end{equation}
where $\pt^1$ and $\pt^2$ are the constituents, $\Delta R_{12}$ is their angular distance. $z_{cut}$ and $\beta$ parameters affect the degree of jet grooming: if $\beta \to \infty$ the jet remains ungroomed. The soft drop algorithm %The $\beta=0$ limit of the energy loss is particularly interesting, since it is largely insensitive to the value of the strong coupling constant. 
The default parameters used by CMS are $\beta=0$ and $z_{cut}=0.1$.

The main grooming algorithm, soft drop, is used in association with PUPPI~\cite{Bertolini2014} in order to remove soft and wide-angle radiations and the pile-up contribution.

\noindent The default soft-drop + PUPPI jet mass suffers from a systematic shift from the expected value of about $\sim 10\%$, and some residual dependence on the jet \pt. Further corrections to the jet mass have been applied:

\begin{enumerate}
  \item[{\bf Gen}:] a \pt-dependent correction to account for a small shift in the generated vector boson mass, applied only on simulated samples
  \item[{\bf Reco}:] a \pt-dependent correction to the reconstructed jet mass, applied separately for jets in the barrel and endcaps regions.
\end{enumerate}

\noindent Figure~\ref{fig:fatjet_pre_softdroppuppimass_ZZ}-~\ref{fig:fatjet_softdroppuppimass} show the jet mass for \W or \Z bosons before and after the correction, without applying any cut on this variable.

\begin{figure}[!htb]
  \begin{center}
    \includegraphics[width=.495\textwidth]{plots/v9/XVZnnPre/FatJet1_softdropPuppiMass_signalZZ.pdf}
    \includegraphics[width=.495\textwidth]{plots/v9/XVZnnPre/FatJet1_softdropPuppiMassCorr_signalZZ.pdf}
  \end{center}
  \caption{Softdrop + PUPPI mass of AK8 jet reconstructed for different bulk graviton signal samples; left: before corrections. right: after corrections.}
  \label{fig:fatjet_pre_softdroppuppimass_ZZ}
\end{figure}

\begin{figure}[!htb]
  \begin{center}
    \includegraphics[width=.495\textwidth]{plots/v9/XVZnnPre/FatJet1_softdropPuppiMass_signalWZ.pdf}
    \includegraphics[width=.495\textwidth]{plots/v9/XVZnnPre/FatJet1_softdropPuppiMassCorr_signalWZ.pdf}
  \end{center}
  \caption{Softdrop + PUPPI mass of AK8 jet reconstructed for different $W^{'}$ signal samples; left: before corrections. right: after corrections.}
  \label{fig:fatjet_pre_softdroppuppimass_ZZ}
\end{figure}

\begin{figure}[!htb]
  \begin{center}
    \includegraphics[width=.495\textwidth]{plots/v9/XVZnnPre/FatJet1_softdropPuppiMass.pdf}
    \includegraphics[width=.495\textwidth]{plots/v9/XVZnnPre/FatJet1_softdropPuppiMassCorr.pdf}
  \end{center}
  \caption{Softdrop + PUPPI mass of AK8 jet; left: before corrections. right: after corrections.}
  \label{fig:fatjet_softdroppuppimass}
\end{figure}

\noindent In order to obtain a better data-Monte Carlo agreement, a smearing procedure has been applied to the soft drop + PUPPI jet mass, by using the stochastic method, with a constant smearing coefficent ($1.00 \pm 0.20$), that does not depend on jet pseudorapidity if it is restricted to $|\eta|<2.5$.

%\clearpage
\subsection{Jet substructure}\label{ssec:jetsub}

In order to further discriminate signal from background, it useful to investigate the inner structure of the jet. Studying the distribution of the jet constituents with respect to the jet axis allows us to test the hypothesis of the existence of multiple substructures, that could be evidence of jets originated by more than one parton. This procedure proceeds as follows: the constituents of the jet are clustered again with the $k_T$ algorithm, however the procedure is stopped when one obtains N subjets. 
Then, a new variable, the N-subjectiness, is introduced. It is defined as:
%\begin{linenomath}\begin{equation}
$$\tau_N = \frac{1}{d_0} \sum_k p_{T,k} min( \Delta R_{1,k}^\beta, \Delta R_{2,k}^\beta, \dots, \Delta R_{N,k}^\beta )$$
%\end{equation}\end{linenomath}
where $\beta$ is an arbitrary parameter, the index $k$ runs over the jet constituents and the distances $\Delta R_{N,k}$ are calculated with respect to the axis of the N-th subjet, obtained by one iteration of $\tau$ minimization by varying the subjet axes around the $k_T$ subjet axes.

The normalization factor $d_0$ is calculated as $d_0 = \sum_k p_{T, k} R_0^\beta$, setting $R_0$ to the radius of the original jet.
The N-subjettiness is always included in the interval from 0 to 1 and represents the compatibility of the jet structure with an N-subjet hypothesis: small values correspond to high compatibility. Indeed, $\tau_N$ weights the transverse momentum of the jet constituents by their angular distance to the closest subjet.
In this analysis the N-subjettiness is calculated from the ungroomed jet with the parameter $\beta=1$. The subjettiness related to the one and two subjet hypothesis is thus:
%\begin{linenomath}\begin{equation}
$$\tau_1 = \frac{1}{d_0} \sum_k p_{T,k} \Delta R_{1,k}$$
%\end{equation}\end{linenomath}
and
%\begin{linenomath}\begin{equation}
$$\tau_2 = \frac{1}{d_0} \sum_k p_{T,k} min( \Delta R_{1,k}, \Delta R_{2,k} )$$
%\end{equation}\end{linenomath}
In principle, these two quantities should allow us to distinguish the dipole-like
nature of the showering of the Higgs decay from the classic monopole structure of
QCD jets. In particular, the variable that best discriminates between V-jets and
QCD jets is the ratio of 2-subjettiness and 1-subjettiness, $\tau_{21} = \tau_2 / \tau_1$.

Figure~\ref{fig:fatjet_pre_tau21} shows the $\tau_{21}$ distributions for the PUPPI algorithm.

\begin{figure}[!htb]
  \begin{center}
    %\includegraphics[width=.495\textwidth]{plots/v9_U/XVZnnInc/FatJet1_puppiTau21.pdf}
  \end{center}
  \caption{$\tau_{21}$ subjettiness of PUPPI AK8 jet after inclusive selections.}
  \label{fig:fatjet_pre_tau21}
\end{figure}



\subsection{b-tagging}\label{ssec:btagging}
 
%The presence of a pair of b-quarks from the $\htobb$ decay is a very distinctive signature that permits a strong discrimination against all the backgrounds that involve jets with light flavors. The only  background which cannot be reduced with this technique is the $\Z$ production in association with one or two b-quarks, and the $\Z \to \bbbar$ decay which is also topologically similar to the signal. The latter can be only reduced by applying a jet mass cut, as described in Section~\ref{ssec:jetmass}.
% 
%Tagging b-jets in boosted topologies has been undergone several modifications with respect to Run-I taggers. 
% One of the most important differences is that the tagger algorithms are not directly based on tracks. 
%%Run-II b-taggers are by default applied on the same charged particle-flow candidate list that is used in the jet clustering (\emph{explicit jet-to-track association}). This procedure is applied to subjets as well: b-tagging algorithms are applied to both the fat-jet and the sub-jets, independently. Furthermore, thanks to the explicit jet-to-track association, the two sub-jets do not share any PF-constituent, avoiding unintended correlations.
B-tagging algorithms are applied to both the fat-jet and the sub-jets, independently. For subjets, run-II taggers are by default applied on the same charged particle-flow candidate list that is used in the jet clustering (\emph{explicit jet-to-track association}). Thanks to the explicit jet-to-track association, the two sub-jets do not share any PF-constituent, avoiding unintended correlations.
% 
% 
%Several algorithms have been developed to tag jets from b-quarks. The recommended and best-performing algorithm is the {\tt pfCombinedInclusiveSecondaryVertexV2BJetTags}, often shortened to \emph{combined secondary vertex (CSV)}. This algorithm involves the use of secondary vertices, together with other lifetime information, like the IP significance or decay lengths. Secondary vertices are reconstructed with the inclusive vertex finder algorithm, that does not require jets (and thus is independent on the jet size) and uses all tracks to reconstruct secondary vertices~\cite{cms:JHEP032011136}. %In order to provide discrimination even when no secondary vertices are found, so the maximum possible b-tagging efficiency is not limited by the secondary vertex reconstruction efficiency ($50 \sim 60\%$). In many cases, tracks with an IP significance $> 2$ can be combined in a so-called pseudo vertex, allowing for the computation of a subset of secondary vertex based quantities even without an actual vertex fit. When even this is not possible, a no vertex category reverts simply to track based variables similarly to the jet probability algorithm. %The list of variables fed as input to an Artificial Neural Network is:
% \begin{itemize}
%   \item  the vertex category (real, pseudo, or no vertex)
%   \item  2D flight distance significance
%   \item  vertex mass
%   \item  number of tracks at the vertex
%   \item  ratio of the energy carried by tracks at the vertex with respect to all tracks in the jet
%   \item  the pseudo-rapidity of the tracks at the vertex with respect to the jet axis
%   \item  2D IP significance of the first track that raises the invariant mass above the charm threshold of 1.5 \GeV when subsequently summing up tracks ordered by decreasing IP significance
%   \item  3D signed IP significances for all tracks in the jet
%   \item  number of tracks in the jet
%   \item  $\Delta R$ between the secondary vertex flight direction and the jet axis
%   \item  number of secondary vertices associated to the jet or sub-jet
% \end{itemize}
 
The jet or sub-jet is considered as tagged if the discriminator value is above some threshold value, often referred to as the cut value, and the efficiency is defined as the number of jets which have a discriminator value that is above that cut divided by the total number of jets (of the same flavor).
% %In other words, the integral of the histogram from a certain discriminator cut up to infinity divided by the total number of jets.
%The typical b-tagging efficiency is between 40\% and 70\% while keeping the rate of mis-identified light-flavor jets between 0.1\% and 10\%. Three working points are usually defined for each algorithm, defining cuts in the discriminators based on the level of mis-tagging. The cut values and the corresponding mis-tagging for light-flavor jets relative to the CSV algorithm are reported in Table~\ref{tab:csvwp}.
% 
% \begin{table}[!htb]
%   \begin{center}
%   \begin{tabular}{lcc}
%   Working point & Cut & $\varepsilon_{light}$\\
%   \hline
%    Loose & 0.605  & $\sim 10\%$ \\
%    Medium & 0.890  & $\sim 1\%$ \\
%    Tight & 0.970  & $\sim 0.1\%$ \\
%   \end{tabular}
%   \end{center}
%   \caption{CSV official working points.}
%   \label{tab:csvwp}
% \end{table}

The b-tagging algorithm used to set the analysis strategy is the Combined Secondary Vertex (CSV)~\cite{bib:btag} discriminator (full name {\tt pfCombinedInclusiveSecondaryVertexV2BJetTags}). Different working points are provided by the POG for Run2 analyses~\cite{BTVPOG}, as shown in table~\ref{tab:btag}, but the only one used in this analysis is the \emph{loose} working point.

\begin{table}[!htb]
  \centering
  \label{tab:btag}
  \begin{tabular}{l|c|c}
     Working point & CSV cut & mis-tag probability\\ 
    \hline
     CSVL (Loose)  & $>0.5426$ & $\approx 10\%$  \\ 
     CSVM (Medium) & $>0.8484$ & $\approx 1\%$   \\ 
     CSVT (Tight)  & $>0.9535$ & $\approx 0.1\%$ \\ 
    \hline
  \end{tabular}
  \caption{Working point for CSV b-tagging algorithm.}
  
\end{table}

B-tagging efficiency is not the same in data and MC. In order to take into account this difference, the BTV POG provides collections of b-tagging scale factors for b-jets and mistagged light jets, measured for different physics processes, for the supported tagging algorithms and the three standard working points~\cite{bib:btag}. A weight is calculated on a per-event basis as a function of the b-tagging status of the jets and their kinematic variables~\cite{bib:btagsf}.%; this is a simple and effective method if there are a small number of possible combinations of jets and b-tagged jets.%Unfortunately, this is not the case of the present analysis. Other techniques allow to take into account the scale factors provided by BTV by \emph{reshaping} the discriminator output; this method has been already successfully applied in the SM VH analysis~\cite{bib:SMVH}, and is also described in detail in Ref.~\cite{bib:AZh,Khachatryan:2015lba}. The reshaping method does not sensibly increase the b-tagging scale factors uncertainty with respect to using single operating point SFs or other techniques used to apply the same scale factors.
% 
% The CSV discriminator output has been reshaped in the simulation taking into account the official SF provided by the POG. The procedure is tested in a \ttbar-enriched sample, obtained by requiring one tight and isolated muon and a tight electron and at least one jet above 30 \GeV. The original and reshaped CSV distribution of the leading  and sub-leading jet in the event are reported in Fig.~\ref{fig:reshaping1} and Fig.~\ref{fig:reshaping2}, respectively for events passing a 0-lepton and 1-electron selections.
% 
% \begin{figure}[!htb]
%   \centering
%     \includegraphics[width=.495\textwidth]{plots/XZhnnInc/bjet1_CSVR.pdf}
%     \includegraphics[width=.495\textwidth]{plots/XZhnnInc/bjet1_CSV.pdf}
%   
%   \caption{Combined Seconday Vertex discriminator before (left) and after (right) the reshaping procedure applied to the highest-CSV AK4 jet in the event in the 0-lepton channel.}
%   \label{fig:reshaping1}
% \end{figure}
% 
% \begin{figure}[!htb]
%   \centering
%     \includegraphics[width=.495\textwidth]{plots/XWhenInc/bjet1_CSV.pdf}
%     \includegraphics[width=.495\textwidth]{plots/XWhenInc/bjet1_CSVR.pdf}
%   \caption{Combined Seconday Vertex discriminator before (left) and after (right) the reshaping procedure applied to the highest-CSV AK4 jet in the event in the 1-electron channel.}
%   \label{fig:reshaping2}
% \end{figure}
% 
% \clearpage

In this analysis, b-tagging is used in order to reject events where a top quark is involved, by asking to the AK4 jets not laying in the AK8 jet cone to be anti b-tagged (in practice, the maximum CSV value allowed is the loose working point, CSVL).

\subsection{Missing Energy}
{\color{red} How the MET is reconstructed}
 
The \MET is the imbalance in the transverse momentum of all visible particles, and it is reconstructed with the particle flow algorithm~\cite{bib:PF1}. The \emph{raw} \MET is defined as the inverse vectorial sum of the transverse momentum of all the reconstructed charged and neutral particle flow candidates: $\vec{\MET}= - \sum_{i=0}^{all} \vec{\pt}_i$.
The raw \MET is systematically different from true \MET, for many reasons including the non-compensating nature of the calorimeters and detector misalignment. To better estimate the true \MET, corrections can be applied:
\begin{itemize}
   \item[\emph{Type-0}:] a mitigation for the degradation of the \MET reconstruction due to the pileup interactions, by applying the CHS algorithm. However, the \MET contribution from pileup neutral particles cannot be easily subtracted; the assumption is that the \MET contribution term of charged and neutral pileup particles are the same, and cancellation at the true level is exact:% $\sum_{neuPU} \vec{\pt}_i^{true} + \sum_{chPU} \vec{\pt}_i^{true} = 0$.
%per qualche motivo non gli piace sta formula
 An additional \MET term is then added to the raw \MET to take into account the neutral PU contribution, which is equal to the charged one with a multiplicative scale factor taking into account calorimeter mismeasurements of low-\pt energy deposits.
   \item[\emph{Type-1}:] propagation of the jet energy corrections (JEC) to MET. The Type-I correction replaces the vector sum of transverse momenta of particles which can be clustered as jets with the vector sum of the transverse momenta of the jets to which JEC is applied. 
 \end{itemize}
% 
Particle flow \MET with type-1 corrections applied is currently the default one used by CMS physics analyses. Additionaly, some \MET filters have been recommended by JETMET POG for Run2 analyses~\cite{JetMETPOG}, in order to remove events with spurios \MET related to detector noise and bad reconstructions.
\begin{itemize}
  \item {\tt HBHENoiseFilter}
  \item {\tt HBHENoiseIsoFilter}
  \item {\tt EcalDeadCellTriggerPrimitiveFilter}
  \item {\tt goodVertices}
  \item {\tt eeBadScFilter} (not recommended for Monte Carlo, hence not applied)
  \item {\tt globalTightHalo2016Filter}
    \item {\tt BadPFMuonFilter}
    \item {\tt BadChargedCandidateFilter}
\end{itemize}

%\section{Re-computation of \MET corrections and uncertainties}
Since the \MET corrections and uncertainties depend on the JEC applied, they are re-computed accordingly following the JETMETPOG recommendation:
\begin{verbatim}
from PhysicsTools.PatUtils.tools.runMETCorrectionsAndUncertainties import
runMetCorAndUncFromMiniAOD
# If you only want to re-correct and get the proper uncertainties
runMetCorAndUncFromMiniAOD(process,
                           isData=True (or False),
                           )
process.p = cms.Path(process.fullPatMetSequence *
   process.yourAnalyzer)

cms.InputTag("slimmedMETs","","YourProcessName")
\end{verbatim}

Figure~\ref{fig:type1_met} show the \MET distribution for data and Monte Carlo after the corrections and filters.
 
 \begin{figure}[!htb]
   \centering
     %\includegraphics[width=.495\textwidth]{plots/v9_U/XVZnnInc/MEt_pt.pdf}
     %\includegraphics[width=.495\textwidth]{plots/v9_U/XVZnnInc/MEt_phi.pdf}
   
   \caption{Type-1 corrected \MET distribution after inclusive selections.}
   \label{fig:type1_met}
 \end{figure}


\clearpage

